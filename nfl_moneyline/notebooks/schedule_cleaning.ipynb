{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6c3475",
   "metadata": {},
   "source": [
    "Ensure no data leaking by replacing post game stats with previous averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7dd0b30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>date</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>Winner</th>\n",
       "      <th>home_pass_cmp</th>\n",
       "      <th>...</th>\n",
       "      <th>surface</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind</th>\n",
       "      <th>game_type</th>\n",
       "      <th>weekday</th>\n",
       "      <th>gametime</th>\n",
       "      <th>location</th>\n",
       "      <th>home_coach</th>\n",
       "      <th>away_coach</th>\n",
       "      <th>referee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014_01_GB_SEA</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-04</td>\n",
       "      <td>SEA</td>\n",
       "      <td>GB</td>\n",
       "      <td>36.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>fieldturf</td>\n",
       "      <td>71.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>REG</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>20:30</td>\n",
       "      <td>Home</td>\n",
       "      <td>Pete Carroll</td>\n",
       "      <td>Mike McCarthy</td>\n",
       "      <td>John Parry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014_01_NO_ATL</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-07</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NO</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>fieldturf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REG</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>13:00</td>\n",
       "      <td>Home</td>\n",
       "      <td>Mike Smith</td>\n",
       "      <td>Sean Payton</td>\n",
       "      <td>Bill Leavy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014_01_CIN_BAL</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-07</td>\n",
       "      <td>BAL</td>\n",
       "      <td>CIN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>CIN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>sportturf</td>\n",
       "      <td>74.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>REG</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>13:00</td>\n",
       "      <td>Home</td>\n",
       "      <td>John Harbaugh</td>\n",
       "      <td>Marvin Lewis</td>\n",
       "      <td>Gene Stetatore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014_01_BUF_CHI</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-07</td>\n",
       "      <td>CHI</td>\n",
       "      <td>BUF</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>BUF</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>grass</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>REG</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>13:00</td>\n",
       "      <td>Home</td>\n",
       "      <td>Marc Trestman</td>\n",
       "      <td>Doug Marrone</td>\n",
       "      <td>Brad Allen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014_01_WAS_HOU</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-07</td>\n",
       "      <td>HOU</td>\n",
       "      <td>WAS</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>grass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REG</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>13:00</td>\n",
       "      <td>Home</td>\n",
       "      <td>Bill O'Brien</td>\n",
       "      <td>Jay Gruden</td>\n",
       "      <td>Jerome Boger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           game_id  season  week        date home_team away_team  home_score  \\\n",
       "0   2014_01_GB_SEA    2014     1  2014-09-04       SEA        GB        36.0   \n",
       "1   2014_01_NO_ATL    2014     1  2014-09-07       ATL        NO        37.0   \n",
       "2  2014_01_CIN_BAL    2014     1  2014-09-07       BAL       CIN        16.0   \n",
       "3  2014_01_BUF_CHI    2014     1  2014-09-07       CHI       BUF        20.0   \n",
       "4  2014_01_WAS_HOU    2014     1  2014-09-07       HOU       WAS        17.0   \n",
       "\n",
       "   away_score Winner  home_pass_cmp  ...    surface  temp  wind  game_type  \\\n",
       "0        16.0    SEA           19.0  ...  fieldturf  71.0  11.0        REG   \n",
       "1        34.0    ATL           31.0  ...  fieldturf   NaN   NaN        REG   \n",
       "2        23.0    CIN           35.0  ...  sportturf  74.0   8.0        REG   \n",
       "3        23.0    BUF           34.0  ...      grass  74.0   3.0        REG   \n",
       "4         6.0    HOU           14.0  ...      grass   NaN   NaN        REG   \n",
       "\n",
       "    weekday  gametime  location     home_coach     away_coach         referee  \n",
       "0  Thursday     20:30      Home   Pete Carroll  Mike McCarthy      John Parry  \n",
       "1    Sunday     13:00      Home     Mike Smith    Sean Payton      Bill Leavy  \n",
       "2    Sunday     13:00      Home  John Harbaugh   Marvin Lewis  Gene Stetatore  \n",
       "3    Sunday     13:00      Home  Marc Trestman   Doug Marrone      Brad Allen  \n",
       "4    Sunday     13:00      Home   Bill O'Brien     Jay Gruden    Jerome Boger  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"../raw/schedules_raw.csv\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6224c04d",
   "metadata": {},
   "source": [
    "Calculate metrics using scheduling data\n",
    "1. Have 2 rows per game, one representing each team\n",
    "2. Replace game data with previous week's data - model will only have access to previous week's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "592d1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def to_team_games(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # clean any stray whitespace in headers\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # columns we must NOT rename\n",
    "    special_keep = {\"home_team\",\"away_team\",\"home_score\",\"away_score\"}\n",
    "\n",
    "    # detect prefixed columns\n",
    "    home_cols_all = [c for c in df.columns if c.startswith(\"home_\")]\n",
    "    away_cols_all = [c for c in df.columns if c.startswith(\"away_\")]\n",
    "\n",
    "    # stats to rename (exclude team name/score)\n",
    "    home_stats = [c for c in home_cols_all if c not in special_keep]\n",
    "    away_stats = [c for c in away_cols_all if c not in special_keep]\n",
    "\n",
    "    # everything else = base/meta (date, lines, stadium, roof, refs, etc.)\n",
    "    base_cols = [c for c in df.columns if c not in (home_stats + away_stats)]\n",
    "\n",
    "    # helpers\n",
    "    def swap_prefix(cols, old, new):\n",
    "        return {c: c.replace(old, new, 1) for c in cols}\n",
    "\n",
    "    # HOME perspective\n",
    "    home_side = (\n",
    "        df[base_cols + home_stats + away_stats]\n",
    "        .rename(columns={\n",
    "            **swap_prefix(home_stats, \"home_\", \"team_\"),\n",
    "            **swap_prefix(away_stats, \"away_\", \"opp_\"),\n",
    "        })\n",
    "        .assign(\n",
    "            team=lambda d: d[\"home_team\"],\n",
    "            opponent=lambda d: d[\"away_team\"],\n",
    "            team_score=lambda d: d[\"home_score\"],\n",
    "            opp_score=lambda d: d[\"away_score\"],\n",
    "            is_home=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # AWAY perspective\n",
    "    away_side = (\n",
    "        df[base_cols + home_stats + away_stats]\n",
    "        .rename(columns={\n",
    "            **swap_prefix(away_stats, \"away_\", \"team_\"),\n",
    "            **swap_prefix(home_stats, \"home_\", \"opp_\"),\n",
    "        })\n",
    "        .assign(\n",
    "            team=lambda d: d[\"away_team\"],\n",
    "            opponent=lambda d: d[\"home_team\"],\n",
    "            team_score=lambda d: d[\"away_score\"],\n",
    "            opp_score=lambda d: d[\"home_score\"],\n",
    "            is_home=0,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    team_games = pd.concat([home_side, away_side], ignore_index=True)\n",
    "\n",
    "    # convenient targets\n",
    "    team_games[\"team_win\"]  = (team_games[\"team_score\"] > team_games[\"opp_score\"]).astype(int)\n",
    "    team_games[\"point_diff\"] = team_games[\"team_score\"] - team_games[\"opp_score\"]\n",
    "\n",
    "    # order columns: core → meta → team_* → opp_*\n",
    "    core = [\"game_id\",\"season\",\"week\",\"date\",\"team\",\"opponent\",\"is_home\",\n",
    "            \"team_score\",\"opp_score\",\"team_win\",\"point_diff\"]\n",
    "    meta = [c for c in base_cols if c not in core]\n",
    "    team_stats = sorted([c for c in team_games.columns if c.startswith(\"team_\")])\n",
    "    opp_stats  = sorted([c for c in team_games.columns if c.startswith(\"opp_\")])\n",
    "\n",
    "    ordered = [c for c in core if c in team_games.columns] + meta + team_stats + opp_stats\n",
    "    return team_games[ordered].sort_values([\"season\",\"week\",\"team\"]).reset_index(drop=True)\n",
    "\n",
    "# usage:\n",
    "# df = pd.read_csv(\"../raw/schedules_raw.csv\")\n",
    "df = to_team_games(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d62fed",
   "metadata": {},
   "source": [
    "Append injury.csv data to the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "91d1da4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 130 injury features.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# capture columns to report what's new at the end\n",
    "_prev_cols = set(df.columns)\n",
    "\n",
    "# --- load & select ---\n",
    "inj = pd.read_csv(\"../raw/injuries_raw.csv\")\n",
    "inj = inj[[\"season\",\"week\",\"team\",\"position\",\"report_status\",\"practice_status\"]].copy()\n",
    "\n",
    "# normalize\n",
    "inj[\"team\"] = inj[\"team\"].astype(str)\n",
    "inj[\"position\"] = inj[\"position\"].str.upper().str.strip()\n",
    "\n",
    "# --- severity mappings ---\n",
    "report_map = {\n",
    "    \"OUT\": 1.00,\n",
    "    \"DOUBTFUL\": 0.75,\n",
    "    \"QUESTIONABLE\": 0.50,\n",
    "    \"PROBABLE\": 0.25,\n",
    "}\n",
    "practice_map = {\n",
    "    \"DID NOT PARTICIPATE IN PRACTICE\": 1.00,\n",
    "    \"LIMITED PARTICIPATION IN PRACTICE\": 0.50,\n",
    "    \"FULL PARTICIPATION IN PRACTICE\": 0.00,\n",
    "}\n",
    "inj[\"report_sev\"]   = inj[\"report_status\"].str.upper().map(report_map).fillna(0.0)\n",
    "inj[\"practice_sev\"] = inj[\"practice_status\"].str.upper().map(practice_map).fillna(0.0)\n",
    "\n",
    "# --- per-position counts (inj_*) ---\n",
    "counts = (\n",
    "    inj.groupby([\"season\",\"week\",\"team\",\"position\"])\n",
    "       .size().unstack(fill_value=0)\n",
    "       .add_prefix(\"inj_\")\n",
    "       .reset_index()\n",
    ")\n",
    "\n",
    "# --- per-position severity (mean) for report/practice (sev_* / prac_sev_*) ---\n",
    "sev_rep = (\n",
    "    inj.groupby([\"season\",\"week\",\"team\",\"position\"])[\"report_sev\"]\n",
    "       .mean().unstack(fill_value=0)\n",
    "       .add_prefix(\"sev_\")\n",
    "       .reset_index()\n",
    ")\n",
    "sev_prac = (\n",
    "    inj.groupby([\"season\",\"week\",\"team\",\"position\"])[\"practice_sev\"]\n",
    "       .mean().unstack(fill_value=0)\n",
    "       .add_prefix(\"prac_sev_\")\n",
    "       .reset_index()\n",
    ")\n",
    "\n",
    "# --- merge onto df ---\n",
    "df = df.merge(counts,  on=[\"season\",\"week\",\"team\"], how=\"left\")\n",
    "df = df.merge(sev_rep, on=[\"season\",\"week\",\"team\"], how=\"left\")\n",
    "df = df.merge(sev_prac,on=[\"season\",\"week\",\"team\"], how=\"left\")\n",
    "\n",
    "# fill any injury-derived NaNs with 0\n",
    "for c in df.columns:\n",
    "    if c.startswith((\"inj_\",\"sev_\",\"prac_sev_\")):\n",
    "        df[c] = df[c].fillna(0.0)\n",
    "\n",
    "# --- grouped features (sensible football buckets) ---\n",
    "def _sum_cols(cols):\n",
    "    present = [c for c in cols if c in df.columns]\n",
    "    return df[present].sum(axis=1) if present else 0.0\n",
    "\n",
    "# position families we might see in the CSV\n",
    "OL = [\"C\",\"G\",\"T\",\"OL\"]                # offensive line\n",
    "DL = [\"DE\",\"DT\",\"NT\",\"DL\"]            # defensive line\n",
    "SKILL = [\"RB\",\"WR\",\"TE\"]              # offensive skill (QB handled separately)\n",
    "SEC = [\"CB\",\"S\",\"DB\"]                 # secondary\n",
    "\n",
    "# counts\n",
    "df[\"inj_qb_flag\"]        = (df.get(\"inj_QB\", 0) > 0).astype(int)\n",
    "df[\"inj_skill\"]          = _sum_cols([f\"inj_{p}\" for p in SKILL])\n",
    "df[\"inj_ol\"]             = _sum_cols([f\"inj_{p}\" for p in OL])\n",
    "df[\"inj_dl\"]             = _sum_cols([f\"inj_{p}\" for p in DL])\n",
    "df[\"inj_secondary\"]      = _sum_cols([f\"inj_{p}\" for p in SEC])\n",
    "df[\"inj_front7\"]         = df[\"inj_dl\"] + df.get(\"inj_LB\", 0)\n",
    "df[\"inj_total\"]          = _sum_cols([c for c in df.columns if c.startswith(\"inj_\")])\n",
    "\n",
    "# severity (report-based)\n",
    "df[\"sev_qb\"]             = df.get(\"sev_QB\", 0.0)\n",
    "df[\"sev_skill_mean\"]     = _sum_cols([f\"sev_{p}\" for p in SKILL]) / np.maximum(1, (df[ [c for c in [f\"inj_{p}\" for p in SKILL] if c in df.columns] ] > 0).sum(axis=1))\n",
    "df[\"sev_ol_mean\"]        = _sum_cols([f\"sev_{p}\" for p in OL])   / np.maximum(1, (df[ [c for c in [f\"inj_{p}\" for p in OL]    if c in df.columns] ] > 0).sum(axis=1))\n",
    "df[\"sev_dl_mean\"]        = _sum_cols([f\"sev_{p}\" for p in DL])   / np.maximum(1, (df[ [c for c in [f\"inj_{p}\" for p in DL]    if c in df.columns] ] > 0).sum(axis=1))\n",
    "df[\"sev_secondary_mean\"] = _sum_cols([f\"sev_{p}\" for p in SEC])  / np.maximum(1, (df[ [c for c in [f\"inj_{p}\" for p in SEC]   if c in df.columns] ] > 0).sum(axis=1))\n",
    "df[\"sev_total_mean\"]     = _sum_cols([c for c in df.columns if c.startswith(\"sev_\")]) / np.maximum(1, (df[ [c for c in df.columns if c.startswith(\"inj_\")] ] > 0).sum(axis=1))\n",
    "\n",
    "# practice severity (optional overall index)\n",
    "df[\"prac_sev_total_mean\"] = _sum_cols([c for c in df.columns if c.startswith(\"prac_sev_\")]) / np.maximum(1, (df[ [c for c in df.columns if c.startswith(\"inj_\")] ] > 0).sum(axis=1))\n",
    "\n",
    "# finalize: replace any remaining inf/NaN from divisions\n",
    "for c in [\"sev_skill_mean\",\"sev_ol_mean\",\"sev_dl_mean\",\"sev_secondary_mean\",\"sev_total_mean\",\"prac_sev_total_mean\"]:\n",
    "    df[c] = df[c].replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "# ========== ONLY ADDITION: leak-safe shift by 1 prior game (TEAM) ==========\n",
    "inj_cols_base = [c for c in df.columns if c.startswith((\"inj_\",\"sev_\",\"prac_sev_\"))]\n",
    "inj_grouped   = [c for c in [\"inj_qb_flag\",\"inj_skill\",\"inj_ol\",\"inj_dl\",\n",
    "                             \"inj_secondary\",\"inj_front7\",\"inj_total\",\n",
    "                             \"sev_qb\",\"sev_skill_mean\",\"sev_ol_mean\",\n",
    "                             \"sev_dl_mean\",\"sev_secondary_mean\",\n",
    "                             \"sev_total_mean\",\"prac_sev_total_mean\"]\n",
    "                 if c in df.columns]\n",
    "inj_all = inj_cols_base + inj_grouped\n",
    "\n",
    "for col in inj_all:\n",
    "    df[f\"{col}_prior1\"] = (\n",
    "        df.sort_values([\"team\",\"season\",\"week\"])\n",
    "          .groupby([\"team\",\"season\"], sort=False)[col]\n",
    "          .shift(1)\n",
    "    )\n",
    "\n",
    "# fill missing priors with 0 (meaning: no info / no injuries last week)\n",
    "prior_cols = [f\"{c}_prior1\" for c in inj_all]\n",
    "\n",
    "for c in prior_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].fillna(0.0)\n",
    "\n",
    "# list of added variables\n",
    "_added_cols = sorted(list(set(df.columns) - _prev_cols))\n",
    "print(f\"Added {len(_added_cols)} injury features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8396bc0",
   "metadata": {},
   "source": [
    "Roll back features to ensure model only has access to past data, adding prior_stats columns as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2f304331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prior_features(\n",
    "    team_games: pd.DataFrame,\n",
    "    cols=None,\n",
    "    group_keys=(\"team\",\"season\"),\n",
    "    order_keys=(\"season\",\"week\",\"date\"),\n",
    "    lags=(1,),\n",
    "    name_style=\"auto\",\n",
    "    fill=None\n",
    "):\n",
    "    g = team_games.copy()\n",
    "\n",
    "    # ensure proper sort for shifting\n",
    "    g[\"week\"] = pd.to_numeric(g[\"week\"], errors=\"ignore\")\n",
    "    g = g.sort_values(list(group_keys) + list(order_keys))\n",
    "\n",
    "    # default: all numeric team_* columns\n",
    "    if cols is None:\n",
    "        cols = [c for c in g.columns if c.startswith(\"team_\") and pd.api.types.is_numeric_dtype(g[c])]\n",
    "\n",
    "    def prior_name(col, lag):\n",
    "        if name_style == \"suffix\":\n",
    "            return f\"{col}_prior{lag}\"\n",
    "        if col.startswith(\"team_\"):\n",
    "            return col.replace(\"team_\", f\"team_prior{'' if lag==1 else f'{lag}_'}\", 1)\n",
    "        return f\"{col}_prior{lag}\"\n",
    "\n",
    "    # compute lags per team-season\n",
    "    for lag in lags:\n",
    "        lagged = (\n",
    "            g.groupby(list(group_keys), group_keys=False)[cols]\n",
    "             .shift(lag)\n",
    "             .rename(columns={c: prior_name(c, lag) for c in cols})\n",
    "        )\n",
    "        g = pd.concat([g, lagged], axis=1)\n",
    "\n",
    "    # optional fill for first game(s) of season\n",
    "    if fill is not None:\n",
    "        new_cols = [prior_name(c, lag) for c in cols for lag in lags]\n",
    "        if fill == \"ffill\":\n",
    "            g[new_cols] = (\n",
    "                g.groupby(list(group_keys), group_keys=False)[new_cols]\n",
    "                 .apply(lambda x: x.ffill())\n",
    "            )\n",
    "        else:\n",
    "            g[new_cols] = g[new_cols].fillna(fill)\n",
    "\n",
    "    # --- NEW: drop duplicate columns ---\n",
    "    g = g.loc[:, ~g.columns.duplicated()]\n",
    "\n",
    "    return g\n",
    "\n",
    "# ---- Team stats to lag ----\n",
    "team_cols_to_lag = [\n",
    "    \"team_pass_att\",\n",
    "    \"team_pass_cmp\",\n",
    "    \"team_pass_yds\",\n",
    "    \"team_pass_td\",\n",
    "    \"team_pass_int\",\n",
    "    \"team_pass_sacked\",\n",
    "    \"team_pass_sacked_yds\",\n",
    "    \n",
    "    \"team_rush_att\",\n",
    "    \"team_rush_yds\",\n",
    "    \"team_rush_td\",\n",
    "    \n",
    "    \"team_first_down\",\n",
    "    \"team_turnovers\",\n",
    "    \n",
    "    \"team_penalties\",\n",
    "    \"team_penalties_yds\",\n",
    "    \n",
    "    \"team_fga\", \"team_fgm\",       # field goals\n",
    "    \"team_xpa\", \"team_xpm\",       # extra points\n",
    "    \n",
    "    \"team_punt\",\n",
    "    \"team_punt_yds\",\n",
    "    \n",
    "    \"team_plays_offense\",\n",
    "    \"team_score\"\n",
    "]\n",
    "\n",
    "# ---- Opponent stats to lag ----\n",
    "opp_cols_to_lag = [\n",
    "    \"opp_pass_att\",\n",
    "    \"opp_pass_cmp\",\n",
    "    \"opp_pass_yds\",\n",
    "    \"opp_pass_td\",\n",
    "    \"opp_pass_int\",\n",
    "    \"opp_pass_sacked\",\n",
    "    \"opp_pass_sacked_yds\",\n",
    "    \n",
    "    \"opp_rush_att\",\n",
    "    \"opp_rush_yds\",\n",
    "    \"opp_rush_td\",\n",
    "    \n",
    "    \"opp_first_down\",\n",
    "    \"opp_turnovers\",\n",
    "    \n",
    "    \"opp_penalties\",\n",
    "    \"opp_penalties_yds\",\n",
    "    \n",
    "    \"opp_fga\", \"opp_fgm\",\n",
    "    \"opp_xpa\", \"opp_xpm\",\n",
    "    \n",
    "    \"opp_punt\",\n",
    "    \"opp_punt_yds\",\n",
    "    \n",
    "    \"opp_plays_offense\",\n",
    "    \"opp_score\"\n",
    "]\n",
    "\n",
    "# Team priors\n",
    "df = add_prior_features(\n",
    "    df,\n",
    "    cols=team_cols_to_lag,\n",
    "    group_keys=(\"team\",\"season\"),\n",
    "    name_style=\"suffix\"\n",
    ")\n",
    "\n",
    "# Opponent priors\n",
    "df = add_prior_features(\n",
    "    df,\n",
    "    cols=opp_cols_to_lag,\n",
    "    group_keys=(\"opponent\",\"season\"),\n",
    "    name_style=\"suffix\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "24b1c762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:30: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:35: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_season\"] = np.where(cnt > 0, csum / cnt, np.nan)\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_season\"] = np.where(cnt > 0, csum / cnt, np.nan)\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_season\"] = np.where(cnt > 0, csum / cnt, np.nan)\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_season\"] = np.where(cnt > 0, csum / cnt, np.nan)\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:56: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:56: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:56: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:56: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:56: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:56: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:56: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:56: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:56: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:56: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:56: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:56: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:56: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:61: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:61: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:61: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:61: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:61: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:61: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:61: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:61: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:61: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:61: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:61: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:61: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"{col}_ewm\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = safe_div(df[a], df[b])\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:132: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:132: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:132: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:132: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:132: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:132: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:132: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:132: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out] = df[tcol] - df[ocol]\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:139: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:137: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"point_diff_roll{w}\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:139: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:137: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"point_diff_roll{w}\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:139: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:137: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"point_diff_roll{w}\"] = (\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1176785295.py:142: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"point_diff_season\"] = np.where(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example: rolling averages for selected features\n",
    "team_roll = [\n",
    "    \"team_pass_yds\", \"team_rush_yds\", \"team_pass_td\",\n",
    "    \"team_rush_td\", \"team_turnovers\", \"team_score\",\n",
    "    # extras\n",
    "    \"team_pass_att\", \"team_rush_att\",\n",
    "    \"team_first_down\", \"team_penalties\",\n",
    "    \"team_plays_offense\",\n",
    "    \"team_pass_sacked\",\n",
    "    \"team_fga\"\n",
    "]\n",
    "\n",
    "opp_roll = [\n",
    "    \"opp_pass_yds\", \"opp_rush_yds\", \"opp_pass_td\",\n",
    "    \"opp_rush_td\", \"opp_turnovers\", \"opp_score\",\n",
    "    # extras\n",
    "    \"opp_pass_att\", \"opp_rush_att\",\n",
    "    \"opp_first_down\", \"opp_penalties\",\n",
    "    \"opp_plays_offense\",\n",
    "    \"opp_pass_sacked\"\n",
    "]\n",
    "\n",
    "# --- roll3 / roll5 / roll10 ---\n",
    "for w in (3, 5, 10):\n",
    "    for col in team_roll:\n",
    "        df[f\"{col}_roll{w}\"] = (\n",
    "            df.groupby(\"team\")[col]\n",
    "              .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
    "        )\n",
    "    for col in opp_roll:\n",
    "        df[f\"{col}_roll{w}\"] = (\n",
    "            df.groupby(\"opponent\")[col]\n",
    "              .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
    "        )\n",
    "\n",
    "# --- season-to-date mean (before current game) ---\n",
    "for col in team_roll:\n",
    "    grp = df.groupby([\"team\",\"season\"], sort=False)[col]\n",
    "    csum = grp.cumsum().shift(1)\n",
    "    cnt  = grp.cumcount()\n",
    "    df[f\"{col}_season\"] = np.where(cnt > 0, csum / cnt, np.nan)\n",
    "\n",
    "for col in opp_roll:\n",
    "    grp = df.groupby([\"opponent\",\"season\"], sort=False)[col]\n",
    "    csum = grp.cumsum().shift(1)\n",
    "    cnt  = grp.cumcount()\n",
    "    df[f\"{col}_season\"] = np.where(cnt > 0, csum / cnt, np.nan)\n",
    "\n",
    "# --- exponentially weighted momentum ---\n",
    "alpha = 0.3\n",
    "for col in team_roll:\n",
    "    df[f\"{col}_ewm\"] = (\n",
    "        df.groupby(\"team\")[col]\n",
    "          .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
    "    )\n",
    "for col in opp_roll:\n",
    "    df[f\"{col}_ewm\"] = (\n",
    "        df.groupby(\"opponent\")[col]\n",
    "          .apply(lambda x: x.shift(1).ewm(alpha=alpha, adjust=False, min_periods=1).mean())\n",
    "    )\n",
    "\n",
    "# ---------- Safe division helper ----------\n",
    "def safe_div(num, den):\n",
    "    return np.where(den.astype(float) != 0, num.astype(float) / den.astype(float), np.nan)\n",
    "\n",
    "# ---------- Windows to compute ----------\n",
    "windows = [\"roll3\", \"roll5\", \"roll10\", \"season\"]\n",
    "\n",
    "def rate_if_exists(lhs_base, rhs_base, out_base, windows):\n",
    "    for w in windows:\n",
    "        a, b, out = f\"{lhs_base}_{w}\", f\"{rhs_base}_{w}\", f\"{out_base}_{w}\"\n",
    "        if a in df.columns and b in df.columns:\n",
    "            df[out] = safe_div(df[a], df[b])\n",
    "\n",
    "# ---------- Team + Opp Efficiency Rates ----------\n",
    "# Yards/attempt\n",
    "rate_if_exists(\"team_pass_yds\", \"team_pass_att\", \"team_pass_ypa\", windows)\n",
    "rate_if_exists(\"opp_pass_yds\",  \"opp_pass_att\",  \"opp_pass_ypa\",  windows)\n",
    "\n",
    "# TD rate\n",
    "rate_if_exists(\"team_pass_td\", \"team_pass_att\", \"team_pass_td_rate\", windows)\n",
    "rate_if_exists(\"opp_pass_td\",  \"opp_pass_att\",  \"opp_pass_td_rate\", windows)\n",
    "\n",
    "# INT rate\n",
    "rate_if_exists(\"team_pass_int\", \"team_pass_att\", \"team_int_rate\", windows)\n",
    "rate_if_exists(\"opp_pass_int\",  \"opp_pass_att\",  \"opp_int_rate\",  windows)\n",
    "\n",
    "# Rush yards/carry\n",
    "rate_if_exists(\"team_rush_yds\", \"team_rush_att\", \"team_rush_ypc\", windows)\n",
    "rate_if_exists(\"opp_rush_yds\",  \"opp_rush_att\",  \"opp_rush_ypc\",  windows)\n",
    "\n",
    "# Play mix\n",
    "rate_if_exists(\"team_pass_att\", \"team_plays_offense\", \"team_pass_rate\", windows)\n",
    "rate_if_exists(\"opp_pass_att\",  \"opp_plays_offense\",  \"opp_pass_rate\",  windows)\n",
    "rate_if_exists(\"team_rush_att\", \"team_plays_offense\", \"team_rush_rate\", windows)\n",
    "rate_if_exists(\"opp_rush_att\",  \"opp_plays_offense\",  \"opp_rush_rate\",  windows)\n",
    "\n",
    "# First-down rate\n",
    "rate_if_exists(\"team_first_down\", \"team_plays_offense\", \"team_fd_rate\", windows)\n",
    "rate_if_exists(\"opp_first_down\",  \"opp_plays_offense\",  \"opp_fd_rate\",  windows)\n",
    "\n",
    "# FG attempt rate\n",
    "rate_if_exists(\"team_fga\", \"team_plays_offense\", \"team_fga_rate\", windows)\n",
    "rate_if_exists(\"opp_fga\",  \"opp_plays_offense\",  \"opp_fga_rate\",  windows)\n",
    "\n",
    "# ---------- Differentials (matchup framing) ----------\n",
    "# Raw stats (example subset)\n",
    "raw_pairs = [\n",
    "    \"pass_yds\",\"rush_yds\",\"pass_td\",\"rush_td\",\"turnovers\",\"score\",\"first_down\"\n",
    "]\n",
    "for stat in raw_pairs:\n",
    "    for w in windows:\n",
    "        tcol, ocol, out = f\"team_{stat}_{w}\", f\"opp_{stat}_{w}\", f\"diff_{stat}_{w}\"\n",
    "        if tcol in df.columns and ocol in df.columns:\n",
    "            df[out] = df[tcol] - df[ocol]\n",
    "\n",
    "# Efficiency differentials\n",
    "eff_pairs = [\"pass_ypa\",\"rush_ypc\",\"pass_td_rate\",\"int_rate\",\"fd_rate\",\"fga_rate\"]\n",
    "for stat in eff_pairs:\n",
    "    for w in windows:\n",
    "        tcol, ocol, out = f\"team_{stat}_{w}\", f\"opp_{stat}_{w}\", f\"diff_{stat}_{w}\"\n",
    "        if tcol in df.columns and ocol in df.columns:\n",
    "            df[out] = df[tcol] - df[ocol]\n",
    "\n",
    "# Mix differentials\n",
    "for stat in [\"pass_rate\",\"rush_rate\"]:\n",
    "    for w in windows:\n",
    "        tcol, ocol, out = f\"team_{stat}_{w}\", f\"opp_{stat}_{w}\", f\"diff_{stat}_{w}\"\n",
    "        if tcol in df.columns and ocol in df.columns:\n",
    "            df[out] = df[tcol] - df[ocol]\n",
    "\n",
    "# ---------- Point Differential windows ----------\n",
    "if \"point_diff\" in df.columns:\n",
    "    for w in (3, 5, 10):\n",
    "        df[f\"point_diff_roll{w}\"] = (\n",
    "            df.groupby(\"team\")[\"point_diff\"]\n",
    "              .apply(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
    "        )\n",
    "    g = df.groupby([\"team\",\"season\"], sort=False)[\"point_diff\"]\n",
    "    df[\"point_diff_season\"] = np.where(\n",
    "        g.cumcount() > 0, g.cumsum().shift(1) / g.cumcount(), np.nan\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "df195555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2969453775.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"team_win_pre\"]   = df.groupby(\"team\")[\"team_win\"].shift(1).cumsum()\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2969453775.py:15: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2969453775.py:19: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2969453775.py:15: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2969453775.py:19: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2969453775.py:15: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2969453775.py:19: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2969453775.py:28: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2969453775.py:28: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2969453775.py:28: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2969453775.py:43: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2969453775.py:43: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2969453775.py:43: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n"
     ]
    }
   ],
   "source": [
    "# 1) Opponent win % BEFORE this game\n",
    "df[\"team_win_pre\"]   = df.groupby(\"team\")[\"team_win\"].shift(1).cumsum()\n",
    "df[\"team_games_pre\"] = df.groupby(\"team\").cumcount()\n",
    "df[\"team_win_pct_pre\"] = np.where(\n",
    "    df[\"team_games_pre\"] > 0, df[\"team_win_pre\"] / df[\"team_games_pre\"], np.nan\n",
    ")\n",
    "\n",
    "# opponent's win% prior to this game (must be lagged!)\n",
    "df[\"opponent_win_pct_pre\"] = df.groupby(\"opponent\")[\"team_win_pct_pre\"].shift(1)\n",
    "\n",
    "# 2) SoS: mean opponent win% over last N games (team & opp mirrors)\n",
    "for w in (3, 5, 10):\n",
    "    df[f\"team_sos_win_pct_roll{w}\"] = (\n",
    "        df.groupby(\"team\")[\"opponent_win_pct_pre\"]\n",
    "          .apply(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
    "    )\n",
    "    df[f\"opp_sos_win_pct_roll{w}\"] = (\n",
    "        df.groupby(\"opponent\")[\"team_win_pct_pre\"]\n",
    "          .apply(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
    "    )\n",
    "\n",
    "# 3) Team rolling point diff (if not already built elsewhere)\n",
    "for w in (3, 5, 10):\n",
    "    col = f\"team_point_diff_roll{w}\"\n",
    "    if col not in df.columns:\n",
    "        df[col] = (\n",
    "            df.groupby(\"team\")[\"point_diff\"]\n",
    "              .apply(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
    "        )\n",
    "\n",
    "# 4) League-average point diff per week, then lagged rolling by SEASON\n",
    "#    (avoids same-week peeking)\n",
    "league_week = (\n",
    "    df.groupby([\"season\",\"week\"], as_index=False)[\"point_diff\"]\n",
    "      .mean()\n",
    "      .rename(columns={\"point_diff\": \"league_avg_pd\"})\n",
    "      .sort_values([\"season\",\"week\"])\n",
    ")\n",
    "\n",
    "for w in (3, 5, 10):\n",
    "    league_week[f\"league_point_diff_roll{w}\"] = (\n",
    "        league_week.groupby(\"season\")[\"league_avg_pd\"]\n",
    "                   .apply(lambda s: s.shift(1).rolling(w, min_periods=1).mean())\n",
    "    )\n",
    "\n",
    "# attach back\n",
    "df = df.merge(league_week, on=[\"season\",\"week\"], how=\"left\")\n",
    "\n",
    "# 5) Adjusted PD = team rolling PD − league rolling PD (same window)\n",
    "for w in (3, 5, 10):\n",
    "    df[f\"team_adj_point_diff_roll{w}\"] = (\n",
    "        df[f\"team_point_diff_roll{w}\"] - df[f\"league_point_diff_roll{w}\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f74d4f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1339401465.py:14: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df.groupby(\"team\")[\"team_win\"].apply(lambda x: calc_streak(x.shift(1).fillna(0), 1))\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1339401465.py:17: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df.groupby(\"team\")[\"team_win\"].apply(lambda x: calc_streak(x.shift(1).fillna(1), 0))\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1339401465.py:25: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).apply(\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1339401465.py:31: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).apply(\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1339401465.py:25: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).apply(\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1339401465.py:31: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).apply(\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1339401465.py:25: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).apply(\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\1339401465.py:31: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(w, min_periods=1).apply(\n"
     ]
    }
   ],
   "source": [
    "# --- Win & loss streaks ---\n",
    "def calc_streak(series, win_val=1):\n",
    "    streak = []\n",
    "    count = 0\n",
    "    for val in series:\n",
    "        if val == win_val:\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 0\n",
    "        streak.append(count)\n",
    "    return pd.Series(streak, index=series.index)\n",
    "\n",
    "df[\"team_win_streak_pre\"] = (\n",
    "    df.groupby(\"team\")[\"team_win\"].apply(lambda x: calc_streak(x.shift(1).fillna(0), 1))\n",
    ")\n",
    "df[\"team_loss_streak_pre\"] = (\n",
    "    df.groupby(\"team\")[\"team_win\"].apply(lambda x: calc_streak(x.shift(1).fillna(1), 0))\n",
    ")\n",
    "\n",
    "# --- Blowout & close-game rates ---\n",
    "for w in (3, 5, 10):\n",
    "    # blowouts: |PD| >= 14\n",
    "    df[f\"blowout_rate_roll{w}\"] = (\n",
    "        df.groupby(\"team\")[\"point_diff\"]\n",
    "          .apply(lambda x: x.shift(1).rolling(w, min_periods=1).apply(\n",
    "              lambda s: np.mean(np.abs(s) >= 14)))\n",
    "    )\n",
    "    # close games: |PD| <= 3\n",
    "    df[f\"close_game_rate_roll{w}\"] = (\n",
    "        df.groupby(\"team\")[\"point_diff\"]\n",
    "          .apply(lambda x: x.shift(1).rolling(w, min_periods=1).apply(\n",
    "              lambda s: np.mean(np.abs(s) <= 3)))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1ad7ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 7) HOME / VENUE / WEATHER\n",
    "# =========================\n",
    "\n",
    "def to_flag(s):  # -> 0/1 Int8, NA -> 0\n",
    "    return s.fillna(False).astype(\"Int8\")\n",
    "\n",
    "if \"temp\" in df.columns:\n",
    "    df[\"temp_bin_le_32\"] = to_flag(df[\"temp\"] <= 32)\n",
    "    df[\"temp_bin_33_60\"] = to_flag((df[\"temp\"] > 32) & (df[\"temp\"] <= 60))\n",
    "    df[\"temp_bin_61_80\"] = to_flag((df[\"temp\"] > 60) & (df[\"temp\"] <= 80))\n",
    "    df[\"temp_bin_gt_80\"] = to_flag(df[\"temp\"] > 80)\n",
    "    df[\"extreme_cold\"]   = to_flag(df[\"temp\"] <= 32)\n",
    "\n",
    "if \"wind\" in df.columns:\n",
    "    df[\"wind2\"] = df[\"wind\"].astype(float) ** 2  # non-linear wind effect\n",
    "\n",
    "if {\"is_home\",\"temp\"}.issubset(df.columns):\n",
    "    # leave float to allow NA in temp\n",
    "    df[\"is_home_x_temp\"] = df[\"is_home\"].astype(float) * df[\"temp\"]\n",
    "\n",
    "if {\"is_home\",\"short_rest\"}.issubset(df.columns):\n",
    "    df[\"is_home_x_short_rest\"] = to_flag(df[\"is_home\"].astype(bool) & df[\"short_rest\"].astype(bool))\n",
    "\n",
    "if \"roof\" in df.columns:\n",
    "    roof_l = df[\"roof\"].astype(\"string\").str.lower()\n",
    "    df[\"roof_dome\"] = to_flag(roof_l.isin([\"dome\",\"indoor\",\"closed\"]))\n",
    "\n",
    "if \"surface\" in df.columns:\n",
    "    surf_l = df[\"surface\"].astype(\"string\").str.lower()\n",
    "    df[\"surface_turf\"] = to_flag(surf_l.str.contains(\"turf|artificial\", na=False, regex=True))\n",
    "\n",
    "# =================================\n",
    "# 8) SEASON CONTEXT & GAME TIMING\n",
    "# =================================\n",
    "\n",
    "if \"week\" in df.columns:\n",
    "    df[\"week_number\"] = df[\"week\"].astype(float)\n",
    "    df[\"week_scaled\"] = df[\"week_number\"] / 18.0\n",
    "    df[\"late_season\"] = to_flag(df[\"week_number\"] >= 14)\n",
    "\n",
    "if {\"team\",\"season\",\"week\",\"team_win\"}.issubset(df.columns):\n",
    "    df[\"team_win_pre\"]   = df.groupby(\"team\")[\"team_win\"].shift(1).cumsum()\n",
    "    df[\"team_games_pre\"] = df.groupby(\"team\").cumcount()\n",
    "    df[\"team_wins_pre\"]  = df[\"team_win_pre\"].fillna(0).astype(int)\n",
    "\n",
    "    if \"late_season\" in df.columns:\n",
    "        df[\"must_win_proxy\"] = to_flag((df[\"team_wins_pre\"] >= 8) & (df[\"late_season\"] == 1))\n",
    "\n",
    "# Divisional flag if you have division info\n",
    "if {\"team_division\",\"opponent_division\"}.issubset(df.columns):\n",
    "    df[\"is_divisional\"] = to_flag(df[\"team_division\"] == df[\"opponent_division\"])\n",
    "\n",
    "# Travel/timezone proxies if available\n",
    "if {\"team_tz\",\"game_tz\"}.issubset(df.columns):\n",
    "    df[\"west_to_east\"] = to_flag(df[\"team_tz\"] > df[\"game_tz\"])\n",
    "    df[\"east_to_west\"] = to_flag(df[\"team_tz\"] < df[\"game_tz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "08654e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2509293458.py:49: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  mu  = grp.apply(lambda s: s.expanding(min_periods=1).mean().shift(1)).reset_index(level=0, drop=True)\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2509293458.py:50: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  sd  = grp.apply(lambda s: s.expanding(min_periods=2).std(ddof=0).shift(1)).reset_index(level=0, drop=True)\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2509293458.py:49: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  mu  = grp.apply(lambda s: s.expanding(min_periods=1).mean().shift(1)).reset_index(level=0, drop=True)\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2509293458.py:50: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  sd  = grp.apply(lambda s: s.expanding(min_periods=2).std(ddof=0).shift(1)).reset_index(level=0, drop=True)\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2509293458.py:49: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  mu  = grp.apply(lambda s: s.expanding(min_periods=1).mean().shift(1)).reset_index(level=0, drop=True)\n",
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\2509293458.py:50: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  sd  = grp.apply(lambda s: s.expanding(min_periods=2).std(ddof=0).shift(1)).reset_index(level=0, drop=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def safe_div(a, b):\n",
    "    a = a.astype(float)\n",
    "    b = b.astype(float)\n",
    "    return np.where(b != 0, a / b, np.nan)\n",
    "\n",
    "# =========================\n",
    "# 10) SPECIAL TEAMS PROXIES\n",
    "# =========================\n",
    "# FG per-play rate + differentials (uses your existing roll windows)\n",
    "for w in (3, 5, 10):\n",
    "    fga_t   = f\"team_fga_roll{w}\"\n",
    "    plays_t = f\"team_plays_offense_roll{w}\"\n",
    "    fga_o   = f\"opp_fga_roll{w}\"\n",
    "    plays_o = f\"opp_plays_offense_roll{w}\"\n",
    "\n",
    "    if fga_t in df.columns and plays_t in df.columns:\n",
    "        df[f\"team_fg_per_play_rate_roll{w}\"] = safe_div(df[fga_t], df[plays_t])\n",
    "\n",
    "    if fga_o in df.columns and plays_o in df.columns:\n",
    "        df[f\"opp_fg_per_play_rate_roll{w}\"]  = safe_div(df[fga_o], df[plays_o])\n",
    "\n",
    "    tcol = f\"team_fg_per_play_rate_roll{w}\"\n",
    "    ocol = f\"opp_fg_per_play_rate_roll{w}\"\n",
    "    if tcol in df.columns and ocol in df.columns:\n",
    "        df[f\"diff_fg_per_play_rate_roll{w}\"] = df[tcol] - df[ocol]\n",
    "\n",
    "# (Optional FG \"make opportunity\" = attempts per game-in-window)\n",
    "# If you want it later: team_fga_roll{w} / w\n",
    "\n",
    "# ================================================\n",
    "# 11) SEASON-TO-DATE Z-SCORES (normalize in-season)\n",
    "# ================================================\n",
    "# We’ll z-score the season-to-date versions you already created:\n",
    "#   team_pass_ypa_season, team_rush_ypc_season, team_fd_rate_season\n",
    "# Mean/STD are computed per season using only PRIOR weeks (shifted).\n",
    "\n",
    "season_stats = [\"team_pass_ypa\", \"team_rush_ypc\", \"team_fd_rate\"]\n",
    "\n",
    "for base in season_stats:\n",
    "    col = f\"{base}_season\"\n",
    "    if col not in df.columns:\n",
    "        continue\n",
    "\n",
    "    # per-season expanding mean/std, both lagged so week N uses data up to N-1\n",
    "    grp = df.groupby(\"season\")[col]\n",
    "    mu  = grp.apply(lambda s: s.expanding(min_periods=1).mean().shift(1)).reset_index(level=0, drop=True)\n",
    "    sd  = grp.apply(lambda s: s.expanding(min_periods=2).std(ddof=0).shift(1)).reset_index(level=0, drop=True)\n",
    "\n",
    "    zname = f\"{base}_season_z\"\n",
    "    df[zname] = np.where((sd.astype(float) > 0) & (~pd.isna(sd)),\n",
    "                         (df[col].astype(float) - mu.astype(float)) / sd.astype(float),\n",
    "                         np.nan)\n",
    "\n",
    "# ==================================================\n",
    "# 12) HIGH-VALUE INTERACTIONS (kept deliberately few)\n",
    "# ==================================================\n",
    "# is_home * team_win_pct_pre\n",
    "if \"is_home\" in df.columns and \"team_win_pct_pre\" in df.columns:\n",
    "    df[\"int_is_home__team_win_pct_pre\"] = df[\"is_home\"].astype(float) * df[\"team_win_pct_pre\"].astype(float)\n",
    "\n",
    "# is_home * diff_pass_ypa_roll5\n",
    "if \"is_home\" in df.columns and \"diff_pass_ypa_roll5\" in df.columns:\n",
    "    df[\"int_is_home__diff_pass_ypa_roll5\"] = df[\"is_home\"].astype(float) * df[\"diff_pass_ypa_roll5\"].astype(float)\n",
    "\n",
    "# short_rest * diff_rush_ypc_roll3\n",
    "if \"short_rest\" in df.columns and \"diff_rush_ypc_roll3\" in df.columns:\n",
    "    # keep as float so missing short_rest doesn’t crash\n",
    "    df[\"int_short_rest__diff_rush_ypc_roll3\"] = df[\"short_rest\"].astype(float) * df[\"diff_rush_ypc_roll3\"].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0c518868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- one-hot encode roof & surface early (cleaning phase) ---\n",
    "if \"roof\" in df.columns:\n",
    "    df[\"roof\"] = df[\"roof\"].astype(str).str.strip().str.lower()\n",
    "if \"surface\" in df.columns:\n",
    "    df[\"surface\"] = df[\"surface\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "df = pd.get_dummies(\n",
    "    df,\n",
    "    columns=[c for c in [\"roof\",\"surface\"] if c in df.columns],\n",
    "    prefix=[\"roof\",\"surface\"],\n",
    "    dummy_na=False\n",
    ")\n",
    "\n",
    "# optional: enforce consistent columns (avoids KeyErrors across train/test)\n",
    "expected_roof = [\"roof_closed\",\"roof_open\",\"roof_outdoors\",\"roof_retractable\",\"roof_dome\"]\n",
    "expected_surface = [\"surface_grass\",\"surface_turf\",\"surface_fieldturf\",\"surface_astroturf\"]\n",
    "\n",
    "for col in expected_roof + expected_surface:\n",
    "    if col not in df.columns:\n",
    "        df[col] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9923acb3",
   "metadata": {},
   "source": [
    "Add point differential metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0eb302ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lmart\\AppData\\Local\\Temp\\ipykernel_12488\\283384497.py:9: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.shift(1).rolling(3, min_periods=1).mean())\n"
     ]
    }
   ],
   "source": [
    "# --- Prior game point differential (1-game lag)\n",
    "df[\"point_diff_prior1\"] = (\n",
    "    df.groupby(\"team\")[\"point_diff\"].shift(1)\n",
    ")\n",
    "\n",
    "# --- Rolling 3-game average point differential\n",
    "df[\"point_diff_roll3\"] = (\n",
    "    df.groupby(\"team\")[\"point_diff\"]\n",
    "      .apply(lambda x: x.shift(1).rolling(3, min_periods=1).mean())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f4fc74c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute averages\n",
    "\n",
    "#impute probablitiy feature without vig\n",
    "import numpy as np\n",
    "\n",
    "def moneyline_to_prob(ml):\n",
    "    \"\"\"Convert American odds to implied probability (with vig).\"\"\"\n",
    "    if ml < 0:\n",
    "        return -ml / (-ml + 100)\n",
    "    else:\n",
    "        return 100 / (ml + 100)\n",
    "\n",
    "def remove_vig_prob(team_ml, opp_ml):\n",
    "    \"\"\"\n",
    "    Convert team/opponent moneylines into normalized probabilities.\n",
    "    Returns (team_prob, opp_prob) with vig removed.\n",
    "    \"\"\"\n",
    "    p_team = moneyline_to_prob(team_ml)\n",
    "    p_opp = moneyline_to_prob(opp_ml)\n",
    "    total = p_team + p_opp\n",
    "    return p_team / total, p_opp / total\n",
    "\n",
    "# --- Apply to your DataFrame ---\n",
    "df[\"team_prob_novig\"], df[\"opp_prob_novig\"] = zip(\n",
    "    *df[[\"team_moneyline\", \"opp_moneyline\"]].apply(\n",
    "        lambda x: remove_vig_prob(x[\"team_moneyline\"], x[\"opp_moneyline\"]), axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdd936a",
   "metadata": {},
   "source": [
    "General Cleaning\n",
    "1. Check for low variability columns\n",
    "2. Check for missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d0973b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant columns: ['team_pass_sacked_yds', 'team_punt', 'team_punt_yds', 'opp_pass_sacked_yds', 'opp_punt', 'opp_punt_yds', 'sev_', 'sev__prior1', 'team_pass_sacked_yds_prior1', 'team_punt_prior1', 'team_punt_yds_prior1', 'opp_pass_sacked_yds_prior1', 'opp_punt_prior1', 'opp_punt_yds_prior1', 'league_avg_pd', 'league_point_diff_roll3', 'league_point_diff_roll5', 'league_point_diff_roll10', 'roof_retractable']\n",
      "Constant columns: ['sev_', 'sev__prior1', 'league_avg_pd', 'league_point_diff_roll3', 'league_point_diff_roll5', 'league_point_diff_roll10', 'roof_retractable']\n",
      "                      column  missing_count  missing_pct\n",
      "0             is_home_x_temp           2008    33.355482\n",
      "1                       wind           2008    33.355482\n",
      "2                       temp           2008    33.355482\n",
      "3                      wind2           2008    33.355482\n",
      "4   diff_pass_td_rate_season            989    16.428571\n",
      "5      diff_rush_rate_season            989    16.428571\n",
      "6       diff_pass_yds_season            989    16.428571\n",
      "7      diff_pass_rate_season            989    16.428571\n",
      "8        diff_fd_rate_season            989    16.428571\n",
      "9        diff_pass_td_season            989    16.428571\n",
      "10      diff_rush_yds_season            989    16.428571\n",
      "11      diff_rush_ypc_season            989    16.428571\n",
      "12       diff_rush_td_season            989    16.428571\n",
      "13      diff_pass_ypa_season            989    16.428571\n",
      "14     diff_turnovers_season            989    16.428571\n",
      "15    diff_first_down_season            989    16.428571\n",
      "16         diff_score_season            675    11.212625\n",
      "17    team_pass_ypa_season_z            543     9.019934\n",
      "18    team_rush_ypc_season_z            543     9.019934\n",
      "19     team_fd_rate_season_z            543     9.019934\n"
     ]
    }
   ],
   "source": [
    "print(\"Constant columns:\", df.columns[df.nunique(dropna=True) <= 1].tolist())\n",
    "\n",
    "const_cols = [\n",
    "    'team_pass_sacked_yds', 'team_punt', 'team_punt_yds',\n",
    "    'opp_pass_sacked_yds', 'opp_punt', 'opp_punt_yds',\n",
    "    'team_pass_sacked_yds_prior1', 'team_punt_prior1', 'team_punt_yds_prior1',\n",
    "    'opp_pass_sacked_yds_prior1', 'opp_punt_prior1', 'opp_punt_yds_prior1'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=const_cols)\n",
    "\n",
    "print(\"Constant columns:\", df.columns[df.nunique(dropna=True) <= 1].tolist())\n",
    "\n",
    "df = df.sort_values([\"season\", \"week\", \"team\"]).reset_index(drop=True)\n",
    "\n",
    "# Assume df is your DataFrame\n",
    "missing = (\n",
    "    df.isna()\n",
    "      .sum()\n",
    "      .reset_index()\n",
    "      .rename(columns={\"index\": \"column\", 0: \"missing_count\"})\n",
    ")\n",
    "\n",
    "# Add % missing\n",
    "missing[\"missing_pct\"] = (missing[\"missing_count\"] / len(df)) * 100\n",
    "\n",
    "# Sort by % missing\n",
    "missing = missing.sort_values(\"missing_pct\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(missing.head(20))  # Top 20 columns with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80804063",
   "metadata": {},
   "source": [
    "Adding feature for number of rest days since last game: rest_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "812a2b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Make sure date is datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Sort so diffs are correct\n",
    "df = df.sort_values(['team', 'season', 'week', 'date'])\n",
    "\n",
    "# Previous game date and season for each team\n",
    "df['__prev_date'] = df.groupby('team')['date'].shift(1)\n",
    "df['__prev_season'] = df.groupby('team')['season'].shift(1)\n",
    "\n",
    "# Rest days only within the same season (avoid giant off-season gaps)\n",
    "rest_days = (df['date'] - df['__prev_date']).dt.days\n",
    "df['rest_days'] = np.where(df['season'].eq(df['__prev_season']), rest_days, np.nan)\n",
    "\n",
    "# Helpful indicators (set to <NA> when rest_days is NaN)\n",
    "df['short_rest'] = (df['rest_days'] <= 6).astype('Int64')\n",
    "df['bye_week']   = (df['rest_days'] >= 13).astype('Int64')\n",
    "df.loc[df['rest_days'].isna(), ['short_rest', 'bye_week']] = pd.NA\n",
    "\n",
    "# Drop helper columns\n",
    "df.drop(columns=['__prev_date','__prev_season'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113633d1",
   "metadata": {},
   "source": [
    "Game and Season Record Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9d131d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Chronological order\n",
    "df = df.sort_values([\"team\", \"season\", \"week\"])\n",
    "g  = df.groupby([\"team\", \"season\"], sort=False)\n",
    "\n",
    "# Previous week's win (within-season)\n",
    "df[\"team_win_prev1\"] = g[\"team_win\"].shift(1).fillna(0).astype(int)\n",
    "\n",
    "# Games played BEFORE this game (0 for season opener)\n",
    "df[\"team_games_played_pre\"] = g.cumcount().astype(int)\n",
    "\n",
    "# Wins BEFORE this game: shift THEN cumsum (within-season)\n",
    "df[\"team_wins_pre\"] = g[\"team_win\"].shift(1).fillna(0).astype(int)\n",
    "df[\"team_wins_pre\"] = g[\"team_wins_pre\"].cumsum().astype(int)\n",
    "\n",
    "# Losses BEFORE this game\n",
    "df[\"team_losses_pre\"] = (df[\"team_games_played_pre\"] - df[\"team_wins_pre\"]).astype(int)\n",
    "\n",
    "# Win% BEFORE this game (NaN for opener; fill 0.0 if you prefer)\n",
    "df[\"team_win_pct_pre\"] = np.where(\n",
    "    df[\"team_games_played_pre\"] > 0,\n",
    "    df[\"team_wins_pre\"] / df[\"team_games_played_pre\"],\n",
    "    np.nan\n",
    ").astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a4aa06",
   "metadata": {},
   "source": [
    "Print to the new intermediate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ea5e8719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             game_id  season  week       date team opponent  is_home  \\\n",
      "0     2014_01_SD_ARI    2014     1 2014-09-08  ARI       SD        1   \n",
      "32   2014_02_ARI_NYG    2014     2 2014-09-14  ARI      NYG        0   \n",
      "64    2014_03_SF_ARI    2014     3 2014-09-21  ARI       SF        1   \n",
      "122  2014_05_ARI_DEN    2014     5 2014-10-05  ARI      DEN        0   \n",
      "152  2014_06_WAS_ARI    2014     6 2014-10-12  ARI      WAS        1   \n",
      "\n",
      "     team_score  opp_score  team_win  ...  roof_retractable point_diff_prior1  \\\n",
      "0          18.0       17.0         1  ...                 0              14.0   \n",
      "32         25.0       14.0         1  ...                 0               8.0   \n",
      "64         23.0       14.0         1  ...                 0             -12.0   \n",
      "122        20.0       41.0         0  ...                 0              12.0   \n",
      "152        30.0       20.0         1  ...                 0              25.0   \n",
      "\n",
      "    team_prob_novig  opp_prob_novig  rest_days short_rest  bye_week  \\\n",
      "0          0.591679        0.408321        NaN       <NA>      <NA>   \n",
      "32         0.478203        0.521797        6.0          1         0   \n",
      "64         0.413907        0.586093        7.0          0         0   \n",
      "122        0.240964        0.759036       14.0          0         1   \n",
      "152        0.680078        0.319922        7.0          0         0   \n",
      "\n",
      "     team_win_prev1 team_games_played_pre  team_losses_pre  \n",
      "0                 0                     0                0  \n",
      "32                1                     1                0  \n",
      "64                1                     2                0  \n",
      "122               1                     3                0  \n",
      "152               0                     4                1  \n",
      "\n",
      "[5 rows x 541 columns]\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "df.to_csv(\"../intermediate/schedules_cleaned.csv\", index=False)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a2c3fc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['game_id', 'season', 'week', 'date', 'team', 'opponent', 'is_home', 'team_score', 'opp_score', 'team_win', 'point_diff', 'home_team', 'away_team', 'home_score', 'away_score', 'Winner', 'spread_line', 'total_line', 'stadium', 'temp', 'wind', 'game_type', 'weekday', 'gametime', 'location', 'referee', 'team_coach', 'team_fga', 'team_fgm', 'team_first_down', 'team_fumbles_lost', 'team_moneyline', 'team_pass_att', 'team_pass_cmp', 'team_pass_int', 'team_pass_sacked', 'team_pass_td', 'team_pass_yds', 'team_penalties', 'team_penalties_yds', 'team_plays_offense', 'team_rush_att', 'team_rush_td', 'team_rush_yds', 'team_turnovers', 'team_xpa', 'team_xpm', 'opp_coach', 'opp_fga', 'opp_fgm', 'opp_first_down', 'opp_fumbles_lost', 'opp_moneyline', 'opp_pass_att', 'opp_pass_cmp', 'opp_pass_int', 'opp_pass_sacked', 'opp_pass_td', 'opp_pass_yds', 'opp_penalties', 'opp_penalties_yds', 'opp_plays_offense', 'opp_rush_att', 'opp_rush_td', 'opp_rush_yds', 'opp_turnovers', 'opp_xpa', 'opp_xpm', 'inj_', 'inj_C', 'inj_CB', 'inj_DE', 'inj_DT', 'inj_FB', 'inj_G', 'inj_K', 'inj_LB', 'inj_LS', 'inj_P', 'inj_QB', 'inj_RB', 'inj_S', 'inj_T', 'inj_TE', 'inj_WR', 'sev_', 'sev_C', 'sev_CB', 'sev_DE', 'sev_DT', 'sev_FB', 'sev_G', 'sev_K', 'sev_LB', 'sev_LS', 'sev_P', 'sev_QB', 'sev_RB', 'sev_S', 'sev_T', 'sev_TE', 'sev_WR', 'prac_sev_', 'prac_sev_C', 'prac_sev_CB', 'prac_sev_DE', 'prac_sev_DT', 'prac_sev_FB', 'prac_sev_G', 'prac_sev_K', 'prac_sev_LB', 'prac_sev_LS', 'prac_sev_P', 'prac_sev_QB', 'prac_sev_RB', 'prac_sev_S', 'prac_sev_T', 'prac_sev_TE', 'prac_sev_WR', 'inj_qb_flag', 'inj_skill', 'inj_ol', 'inj_dl', 'inj_secondary', 'inj_front7', 'inj_total', 'sev_qb', 'sev_skill_mean', 'sev_ol_mean', 'sev_dl_mean', 'sev_secondary_mean', 'sev_total_mean', 'prac_sev_total_mean', 'inj__prior1', 'inj_C_prior1', 'inj_CB_prior1', 'inj_DE_prior1', 'inj_DT_prior1', 'inj_FB_prior1', 'inj_G_prior1', 'inj_K_prior1', 'inj_LB_prior1', 'inj_LS_prior1', 'inj_P_prior1', 'inj_QB_prior1', 'inj_RB_prior1', 'inj_S_prior1', 'inj_T_prior1', 'inj_TE_prior1', 'inj_WR_prior1', 'sev__prior1', 'sev_C_prior1', 'sev_CB_prior1', 'sev_DE_prior1', 'sev_DT_prior1', 'sev_FB_prior1', 'sev_G_prior1', 'sev_K_prior1', 'sev_LB_prior1', 'sev_LS_prior1', 'sev_P_prior1', 'sev_QB_prior1', 'sev_RB_prior1', 'sev_S_prior1', 'sev_T_prior1', 'sev_TE_prior1', 'sev_WR_prior1', 'prac_sev__prior1', 'prac_sev_C_prior1', 'prac_sev_CB_prior1', 'prac_sev_DE_prior1', 'prac_sev_DT_prior1', 'prac_sev_FB_prior1', 'prac_sev_G_prior1', 'prac_sev_K_prior1', 'prac_sev_LB_prior1', 'prac_sev_LS_prior1', 'prac_sev_P_prior1', 'prac_sev_QB_prior1', 'prac_sev_RB_prior1', 'prac_sev_S_prior1', 'prac_sev_T_prior1', 'prac_sev_TE_prior1', 'prac_sev_WR_prior1', 'inj_qb_flag_prior1', 'inj_skill_prior1', 'inj_ol_prior1', 'inj_dl_prior1', 'inj_secondary_prior1', 'inj_front7_prior1', 'inj_total_prior1', 'sev_qb_prior1', 'sev_skill_mean_prior1', 'sev_ol_mean_prior1', 'sev_dl_mean_prior1', 'sev_secondary_mean_prior1', 'sev_total_mean_prior1', 'prac_sev_total_mean_prior1', 'team_pass_att_prior1', 'team_pass_cmp_prior1', 'team_pass_yds_prior1', 'team_pass_td_prior1', 'team_pass_int_prior1', 'team_pass_sacked_prior1', 'team_rush_att_prior1', 'team_rush_yds_prior1', 'team_rush_td_prior1', 'team_first_down_prior1', 'team_turnovers_prior1', 'team_penalties_prior1', 'team_penalties_yds_prior1', 'team_fga_prior1', 'team_fgm_prior1', 'team_xpa_prior1', 'team_xpm_prior1', 'team_plays_offense_prior1', 'team_score_prior1', 'opp_pass_att_prior1', 'opp_pass_cmp_prior1', 'opp_pass_yds_prior1', 'opp_pass_td_prior1', 'opp_pass_int_prior1', 'opp_pass_sacked_prior1', 'opp_rush_att_prior1', 'opp_rush_yds_prior1', 'opp_rush_td_prior1', 'opp_first_down_prior1', 'opp_turnovers_prior1', 'opp_penalties_prior1', 'opp_penalties_yds_prior1', 'opp_fga_prior1', 'opp_fgm_prior1', 'opp_xpa_prior1', 'opp_xpm_prior1', 'opp_plays_offense_prior1', 'opp_score_prior1', 'team_pass_yds_roll3', 'team_rush_yds_roll3', 'team_pass_td_roll3', 'team_rush_td_roll3', 'team_turnovers_roll3', 'team_score_roll3', 'team_pass_att_roll3', 'team_rush_att_roll3', 'team_first_down_roll3', 'team_penalties_roll3', 'team_plays_offense_roll3', 'team_pass_sacked_roll3', 'team_fga_roll3', 'opp_pass_yds_roll3', 'opp_rush_yds_roll3', 'opp_pass_td_roll3', 'opp_rush_td_roll3', 'opp_turnovers_roll3', 'opp_score_roll3', 'opp_pass_att_roll3', 'opp_rush_att_roll3', 'opp_first_down_roll3', 'opp_penalties_roll3', 'opp_plays_offense_roll3', 'opp_pass_sacked_roll3', 'team_pass_yds_roll5', 'team_rush_yds_roll5', 'team_pass_td_roll5', 'team_rush_td_roll5', 'team_turnovers_roll5', 'team_score_roll5', 'team_pass_att_roll5', 'team_rush_att_roll5', 'team_first_down_roll5', 'team_penalties_roll5', 'team_plays_offense_roll5', 'team_pass_sacked_roll5', 'team_fga_roll5', 'opp_pass_yds_roll5', 'opp_rush_yds_roll5', 'opp_pass_td_roll5', 'opp_rush_td_roll5', 'opp_turnovers_roll5', 'opp_score_roll5', 'opp_pass_att_roll5', 'opp_rush_att_roll5', 'opp_first_down_roll5', 'opp_penalties_roll5', 'opp_plays_offense_roll5', 'opp_pass_sacked_roll5', 'team_pass_yds_roll10', 'team_rush_yds_roll10', 'team_pass_td_roll10', 'team_rush_td_roll10', 'team_turnovers_roll10', 'team_score_roll10', 'team_pass_att_roll10', 'team_rush_att_roll10', 'team_first_down_roll10', 'team_penalties_roll10', 'team_plays_offense_roll10', 'team_pass_sacked_roll10', 'team_fga_roll10', 'opp_pass_yds_roll10', 'opp_rush_yds_roll10', 'opp_pass_td_roll10', 'opp_rush_td_roll10', 'opp_turnovers_roll10', 'opp_score_roll10', 'opp_pass_att_roll10', 'opp_rush_att_roll10', 'opp_first_down_roll10', 'opp_penalties_roll10', 'opp_plays_offense_roll10', 'opp_pass_sacked_roll10', 'team_pass_yds_season', 'team_rush_yds_season', 'team_pass_td_season', 'team_rush_td_season', 'team_turnovers_season', 'team_score_season', 'team_pass_att_season', 'team_rush_att_season', 'team_first_down_season', 'team_penalties_season', 'team_plays_offense_season', 'team_pass_sacked_season', 'team_fga_season', 'opp_pass_yds_season', 'opp_rush_yds_season', 'opp_pass_td_season', 'opp_rush_td_season', 'opp_turnovers_season', 'opp_score_season', 'opp_pass_att_season', 'opp_rush_att_season', 'opp_first_down_season', 'opp_penalties_season', 'opp_plays_offense_season', 'opp_pass_sacked_season', 'team_pass_yds_ewm', 'team_rush_yds_ewm', 'team_pass_td_ewm', 'team_rush_td_ewm', 'team_turnovers_ewm', 'team_score_ewm', 'team_pass_att_ewm', 'team_rush_att_ewm', 'team_first_down_ewm', 'team_penalties_ewm', 'team_plays_offense_ewm', 'team_pass_sacked_ewm', 'team_fga_ewm', 'opp_pass_yds_ewm', 'opp_rush_yds_ewm', 'opp_pass_td_ewm', 'opp_rush_td_ewm', 'opp_turnovers_ewm', 'opp_score_ewm', 'opp_pass_att_ewm', 'opp_rush_att_ewm', 'opp_first_down_ewm', 'opp_penalties_ewm', 'opp_plays_offense_ewm', 'opp_pass_sacked_ewm', 'team_pass_ypa_roll3', 'team_pass_ypa_roll5', 'team_pass_ypa_roll10', 'team_pass_ypa_season', 'opp_pass_ypa_roll3', 'opp_pass_ypa_roll5', 'opp_pass_ypa_roll10', 'opp_pass_ypa_season', 'team_pass_td_rate_roll3', 'team_pass_td_rate_roll5', 'team_pass_td_rate_roll10', 'team_pass_td_rate_season', 'opp_pass_td_rate_roll3', 'opp_pass_td_rate_roll5', 'opp_pass_td_rate_roll10', 'opp_pass_td_rate_season', 'team_rush_ypc_roll3', 'team_rush_ypc_roll5', 'team_rush_ypc_roll10', 'team_rush_ypc_season', 'opp_rush_ypc_roll3', 'opp_rush_ypc_roll5', 'opp_rush_ypc_roll10', 'opp_rush_ypc_season', 'team_pass_rate_roll3', 'team_pass_rate_roll5', 'team_pass_rate_roll10', 'team_pass_rate_season', 'opp_pass_rate_roll3', 'opp_pass_rate_roll5', 'opp_pass_rate_roll10', 'opp_pass_rate_season', 'team_rush_rate_roll3', 'team_rush_rate_roll5', 'team_rush_rate_roll10', 'team_rush_rate_season', 'opp_rush_rate_roll3', 'opp_rush_rate_roll5', 'opp_rush_rate_roll10', 'opp_rush_rate_season', 'team_fd_rate_roll3', 'team_fd_rate_roll5', 'team_fd_rate_roll10', 'team_fd_rate_season', 'opp_fd_rate_roll3', 'opp_fd_rate_roll5', 'opp_fd_rate_roll10', 'opp_fd_rate_season', 'team_fga_rate_roll3', 'team_fga_rate_roll5', 'team_fga_rate_roll10', 'team_fga_rate_season', 'diff_pass_yds_roll3', 'diff_pass_yds_roll5', 'diff_pass_yds_roll10', 'diff_pass_yds_season', 'diff_rush_yds_roll3', 'diff_rush_yds_roll5', 'diff_rush_yds_roll10', 'diff_rush_yds_season', 'diff_pass_td_roll3', 'diff_pass_td_roll5', 'diff_pass_td_roll10', 'diff_pass_td_season', 'diff_rush_td_roll3', 'diff_rush_td_roll5', 'diff_rush_td_roll10', 'diff_rush_td_season', 'diff_turnovers_roll3', 'diff_turnovers_roll5', 'diff_turnovers_roll10', 'diff_turnovers_season', 'diff_score_roll3', 'diff_score_roll5', 'diff_score_roll10', 'diff_score_season', 'diff_first_down_roll3', 'diff_first_down_roll5', 'diff_first_down_roll10', 'diff_first_down_season', 'diff_pass_ypa_roll3', 'diff_pass_ypa_roll5', 'diff_pass_ypa_roll10', 'diff_pass_ypa_season', 'diff_rush_ypc_roll3', 'diff_rush_ypc_roll5', 'diff_rush_ypc_roll10', 'diff_rush_ypc_season', 'diff_pass_td_rate_roll3', 'diff_pass_td_rate_roll5', 'diff_pass_td_rate_roll10', 'diff_pass_td_rate_season', 'diff_fd_rate_roll3', 'diff_fd_rate_roll5', 'diff_fd_rate_roll10', 'diff_fd_rate_season', 'diff_pass_rate_roll3', 'diff_pass_rate_roll5', 'diff_pass_rate_roll10', 'diff_pass_rate_season', 'diff_rush_rate_roll3', 'diff_rush_rate_roll5', 'diff_rush_rate_roll10', 'diff_rush_rate_season', 'point_diff_roll3', 'point_diff_roll5', 'point_diff_roll10', 'point_diff_season', 'team_win_pre', 'team_games_pre', 'team_win_pct_pre', 'opponent_win_pct_pre', 'team_sos_win_pct_roll3', 'opp_sos_win_pct_roll3', 'team_sos_win_pct_roll5', 'opp_sos_win_pct_roll5', 'team_sos_win_pct_roll10', 'opp_sos_win_pct_roll10', 'team_point_diff_roll3', 'team_point_diff_roll5', 'team_point_diff_roll10', 'league_avg_pd', 'league_point_diff_roll3', 'league_point_diff_roll5', 'league_point_diff_roll10', 'team_adj_point_diff_roll3', 'team_adj_point_diff_roll5', 'team_adj_point_diff_roll10', 'team_win_streak_pre', 'team_loss_streak_pre', 'blowout_rate_roll3', 'close_game_rate_roll3', 'blowout_rate_roll5', 'close_game_rate_roll5', 'blowout_rate_roll10', 'close_game_rate_roll10', 'temp_bin_le_32', 'temp_bin_33_60', 'temp_bin_61_80', 'temp_bin_gt_80', 'extreme_cold', 'wind2', 'is_home_x_temp', 'roof_dome', 'surface_turf', 'week_number', 'week_scaled', 'late_season', 'team_wins_pre', 'must_win_proxy', 'team_fg_per_play_rate_roll3', 'team_fg_per_play_rate_roll5', 'team_fg_per_play_rate_roll10', 'team_pass_ypa_season_z', 'team_rush_ypc_season_z', 'team_fd_rate_season_z', 'int_is_home__team_win_pct_pre', 'int_is_home__diff_pass_ypa_roll5', 'roof_closed', 'roof_dome', 'roof_open', 'roof_outdoors', 'surface_a_turf', 'surface_astroplay', 'surface_astroturf', 'surface_fieldturf', 'surface_grass', 'surface_matrixturf', 'surface_nan', 'surface_sportturf', 'roof_retractable', 'point_diff_prior1', 'team_prob_novig', 'opp_prob_novig', 'rest_days', 'short_rest', 'bye_week', 'team_win_prev1', 'team_games_played_pre', 'team_losses_pre']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
